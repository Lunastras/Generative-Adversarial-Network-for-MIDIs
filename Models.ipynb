{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import mido as md\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Dropout, LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "\n",
    "#how many notes to generate\n",
    "output_filepath = \"composedSongs\"\n",
    "\n",
    "latent_dim = 1000\n",
    "disc_loss = []\n",
    "gen_loss = []\n",
    "\n",
    "network_input = np.load(\"inputs_150.npy\")\n",
    "#network_input = np.load(\"inputs_mogus.npy\")\n",
    "\n",
    "\n",
    "#labels will not be needed for this network\n",
    "#network_output = np.load(\"labels_50.npy\") \n",
    "\n",
    "normalization_values = np.load(\"normalization_values.npy\")\n",
    "\n",
    "seq_shape = (network_input.shape[1], network_input.shape[2])\n",
    "\n",
    "biggest_note = normalization_values[0]\n",
    "smallest_note = normalization_values[1]\n",
    "std_note = normalization_values[2]\n",
    "\n",
    "biggest_time = normalization_values[3]\n",
    "smallest_time = normalization_values[4]\n",
    "std_time = normalization_values[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old generator\n",
    "###def get_generator():\n",
    "###        model = Sequential()\n",
    "###        model.add(Dense(256, input_dim=latent_dim))\n",
    "###        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "###        model.add(BatchNormalization(momentum=0.8))\n",
    "###        model.add(Dense(512))\n",
    "###        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "###        model.add(BatchNormalization(momentum=0.8))\n",
    "###        model.add(Dense(1024))\n",
    "###        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "###        model.add(BatchNormalization(momentum=0.8))\n",
    "###        model.add(Dense(np.prod(seq_shape), activation='sigmoid'))\n",
    "###        model.add(Reshape(seq_shape))\n",
    "###       \n",
    "###        noise = Input(shape=(latent_dim,))\n",
    "###        seq = model(noise)\n",
    "###   \n",
    "###        return Model(noise, seq)\n",
    "\n",
    "def get_generator():\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(256, input_dim=latent_dim))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        model.add(Dense(512))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Dense(1024))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))        \n",
    "        model.add(Dropout(0.3))     \n",
    "        \n",
    "        model.add(Dense(1024))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))        \n",
    "        model.add(Dropout(0.3))   \n",
    "        \n",
    "        model.add(Dense(np.prod(seq_shape), activation='sigmoid'))\n",
    "        model.add(Reshape(seq_shape))\n",
    "       \n",
    "        noise = Input(shape=(latent_dim,))\n",
    "        seq = model(noise)\n",
    "   \n",
    "        return Model(noise, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=seq_shape, return_sequences=True))\n",
    "    model.add(Bidirectional(LSTM(512)))\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.2))   \n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.2))   \n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    seq = Input(shape = seq_shape)\n",
    "    validity = model(seq)\n",
    "    \n",
    "    return Model(seq, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(model, num_epochs=50, batch_size=32):\n",
    "    filepath = \"generator/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                      filepath, monitor='loss' \n",
    "                    , verbose=0        \n",
    "                    , save_best_only=True        \n",
    "                    , mode='min')    \n",
    "    callbacks_list = [checkpoint]     \n",
    "    model.fit(network_input, network_output, epochs=num_epochs, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, generation_length=100):\n",
    "    start = np.random.randint(0, len(network_input) - 1)   \n",
    "    pattern = network_input[start]\n",
    "    \n",
    "    prediction_output = []\n",
    "    \n",
    "    for note_index in range(generation_length):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 2))\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        \n",
    "        pattern = pattern[1:len(pattern)]\n",
    "        pattern = np.append(pattern, prediction, axis=0)\n",
    "        prediction_output.append(prediction[0])\n",
    "        \n",
    "    prediction_output = np.reshape(prediction_output, (generation_length, 2))\n",
    "    \n",
    "    return prediction_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss():\n",
    "       # figure(figsize=(8, 6), dpi=80)\n",
    "        plt.plot(disc_loss, c='red')\n",
    "        plt.plot(gen_loss, c='blue')\n",
    "        plt.title(\"GAN Loss per Epoch\")  \n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig('GAN_Loss_per_Epoch_final3.png', transparent=True)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, combined, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Training the model\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # Training the discriminator\n",
    "            # Select a random batch of note sequences\n",
    "            idx = np.random.randint(0, network_input.shape[0], batch_size)\n",
    "            real_seqs = network_input[idx]\n",
    "\n",
    "            #noise = np.random.choice(range(484), (batch_size, self.latent_dim))\n",
    "            #noise = (noise-242)/242\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "            # Generate a batch of new note sequences\n",
    "            gen_seqs = generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = discriminator.train_on_batch(real_seqs, real)\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_seqs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            #  Training the Generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as real)\n",
    "            g_loss = combined.train_on_batch(noise, real)\n",
    "\n",
    "            # Print the progress and save into loss lists\n",
    "            if epoch % sample_interval == 0:\n",
    "                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "                \n",
    "                generator.save_weights('checkpoints/generator', overwrite = True)\n",
    "                discriminator.save_weights('checkpoints/discriminator', overwrite = True)\n",
    "                combined.save_weights('checkpoints/combined', overwrite = True)\n",
    "                disc_loss.append(d_loss[0])\n",
    "                gen_loss.append(g_loss)\n",
    "                \n",
    "                np.save(\"disc_loss.npy\", disc_loss)\n",
    "                np.save(\"gen_loss.npy\", gen_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gan():\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "    \n",
    "    # Build and compile the discriminator\n",
    "    discriminator = get_discriminator()\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # Build the generator\n",
    "    generator = get_generator()\n",
    "    \n",
    "    # The generator takes noise as input and generates note sequences\n",
    "    z = Input(shape=(latent_dim,))\n",
    "    generated_seq = generator(z)\n",
    "    \n",
    "    # For the combined model we will only train the generator\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    # The discriminator takes generated images as input and determines validity\n",
    "    validity = discriminator(generated_seq)\n",
    "    \n",
    "    # The combined model  (stacked generator and discriminator)\n",
    "    # Trains the generator to fool the discriminator\n",
    "    combined = Model(z, validity)\n",
    "    combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    return generator, discriminator, combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output, vel=64, time_scale=1):\n",
    "    mid = md.MidiFile()\n",
    "    track = md.MidiTrack()\n",
    "    mid.tracks.append(track)\n",
    "    prediction_output_aux = np.empty_like(prediction_output)\n",
    "    \n",
    "    #copy the array\n",
    "    prediction_output_aux[:] = prediction_output\n",
    "    \n",
    "    \n",
    "    #queue we will use to end each note\n",
    "    notes_queue = []\n",
    "    \n",
    "    #after how many notes the current note in the queue will end\n",
    "    note_end_interval = 8\n",
    "    \n",
    "    #convert the data into valid values \n",
    "    #for generating a midi\n",
    "    for pair in prediction_output_aux:\n",
    "        \n",
    "        #Denormalise data\n",
    "        pair[0] = round(pair[0] * std_note + smallest_note)\n",
    "        pair[1] = round((pair[1] * std_time + smallest_time) * time_scale) \n",
    "        \n",
    "        pitch = pair.astype(int)[0]\n",
    "        ticks = int(pair[1])\n",
    "\n",
    "        print(pair)\n",
    "        msg = md.Message( 'note_on'\n",
    "                         , note = pitch\n",
    "                         , time = ticks\n",
    "                         , velocity=vel )\n",
    "        \n",
    "        notes_queue.append(pitch)\n",
    "        \n",
    "        if len(notes_queue) == note_end_interval:\n",
    "            end_msg = md.Message( 'note_off'\n",
    "                                 , note = notes_queue[0]\n",
    "                                 , time = 0\n",
    "                                 , velocity=0 )\n",
    "            track.append(end_msg)\n",
    "            del notes_queue[0]\n",
    "                     \n",
    "        track.append(msg)\n",
    "    \n",
    "    #mid.save((output_filepath + '/generatedSong.mid'))\n",
    "    \n",
    "    for note_pitch in notes_queue:\n",
    "        end_msg = md.Message( 'note_off'\n",
    "                             , note = note_pitch\n",
    "                             , time = 100\n",
    "                             , velocity=0 )\n",
    "        track.append(end_msg)\n",
    "       \n",
    "   # for msg in mid:\n",
    "      #  print(msg)\n",
    "        \n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint():\n",
    "    generator.load_weights('checkpoints/generator')\n",
    "    discriminator.load_weights('checkpoints/discriminator')\n",
    "    combined.load_weights('checkpoints/combined')\n",
    "    gen_loss = np.load('gen_loss.npy').tolist()\n",
    "    disc_loss = np.load('disc_loss.npy').tolist()\n",
    "\n",
    "generator, discriminator, combined = get_gan()\n",
    "\n",
    "load_checkpoint()\n",
    "    \n",
    "#resume training\n",
    " ##  generator.load_weights('checkpoints/generator')\n",
    " ##  discriminator.load_weights('checkpoints/discriminator')\n",
    " ##  combined.load_weights('checkpoints/combined')\n",
    "\n",
    " ##  gen_loss = np.load('gen_loss.npy').tolist()\n",
    " ##  disc_loss = np.load('disc_loss.npy').tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training 1: 5000 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 2: same\n",
    "training 3: 5000 epochs, batch_size = 16, optimizer optimizer = Adam(0.001, 0.5)\n",
    "training 4: 1775 epochs, batch_size = 32, optimizer optimizer = Adam(0.001, 0.5)\n",
    "training 4: 2115 epochs, batch_size = 32, optimizer optimizer = Adam(0.001, 0.5)\n",
    "\n",
    "**new model 1\n",
    "training 1: 1600 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 2: 5000 epochs, batch_size = 32, optimizer optimizer = Adam(0.0001, 0.5)\n",
    "\n",
    "**new model 2\n",
    "training 1: 140 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 2: 190 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 3: 1385 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 4: 800 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 5: 1380 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 6: 40 epochs, batch_size = 32, optimizer optimizer = Adam(0.002, 0.5)\n",
    "training 7: 1100 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 8: 630 epochs, batch_size = 32, optimizer optimizer = Adam(0.0006, 0.5)\n",
    "training 9: 4260  epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 10: 125  epochs, batch_size = 32, optimizer optimizer = Adam(0.0001, 0.5)\n",
    "training 11: ---  epochs, batch_size = 32, optimizer optimizer = Adam(0.0004, 0.5)\n",
    "\n",
    "**new model 3\n",
    "training 1: 5000 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 2: 5000 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 3: 2645 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 4: 3240 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5) \n",
    "training 5: 1000 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5) \n",
    "training 6: 4080 epochs, batch_size = 32, optimizer optimizer = Adam(0.0008, 0.5) \n",
    "\n",
    "**new model 4\n",
    "training 1: 20,000 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5) \n",
    "training 2: 1660  epochs, batch_size = 32, optimizer optimizer = Adam(0.001, 0.5) \n",
    "training 3: 10,000  epochs, batch_size = 32, optimizer optimizer = Adam(0.002, 0.5) \n",
    "training 4: 2870   epochs, batch_size = 32, optimizer optimizer = Adam(0.02, 0.5) \n",
    "training 5: 360   epochs, batch_size = 32, optimizer optimizer = Adam(0.002, 0.5) \n",
    "training 6: ---   epochs, batch_size = 32, optimizer optimizer = Adam(0.2, 0.5) \n",
    "\n",
    "**new model 5\n",
    "training 1: 20,000 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 2: 9220 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5) \n",
    "training 3: --- epochs, batch_size = 32, optimizer optimizer = Adam(0.00002, 0.5) \n",
    "\n",
    "**new model 6\n",
    "training 1: 4000 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)\n",
    "training 2: 20000 epochs, batch_size = 32, optimizer optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change learning rate of the models\n",
    "from tensorflow.keras import backend as K\n",
    "learning_rate = 0.0002\n",
    "K.set_value(combined.optimizer.learning_rate, learning_rate)\n",
    "K.set_value(discriminator.optimizer.learning_rate, learning_rate)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_gan(generator, discriminator, combined, epochs=20000, batch_size=32, sample_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "\n",
    "# Generate a batch of new note sequences\n",
    "gen_seqs = generator.predict(noise)\n",
    "#midi = convert_to_midi(gen_seqs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59. 317.]\n",
      "[  70. 1391.]\n",
      "[ 42. 955.]\n",
      "[ 35. 577.]\n",
      "[ 49. 861.]\n",
      "[ 50. 257.]\n",
      "[ 40. 458.]\n",
      "[ 67. 285.]\n",
      "[ 49. 298.]\n",
      "[ 46. 321.]\n",
      "[ 88. 442.]\n",
      "[ 96. 433.]\n",
      "[100. 391.]\n",
      "[ 90. 153.]\n",
      "[ 82. 457.]\n",
      "[ 40. 341.]\n",
      "[ 30. 358.]\n",
      "[ 44. 460.]\n",
      "[ 59. 592.]\n",
      "[ 85. 764.]\n",
      "[  61. 1252.]\n",
      "[ 64. 705.]\n",
      "[ 48. 797.]\n",
      "[ 40. 932.]\n",
      "[ 74. 769.]\n",
      "[  77. 1385.]\n",
      "[ 39. 260.]\n",
      "[ 50. 603.]\n",
      "[ 52. 563.]\n",
      "[ 67. 681.]\n",
      "[ 91. 653.]\n",
      "[ 88. 655.]\n",
      "[ 62. 529.]\n",
      "[ 39. 710.]\n",
      "[ 41. 526.]\n",
      "[ 55. 374.]\n",
      "[ 39. 256.]\n",
      "[ 36. 197.]\n",
      "[ 32. 383.]\n",
      "[ 39. 770.]\n",
      "[ 36. 263.]\n",
      "[ 30. 582.]\n",
      "[ 31. 381.]\n",
      "[ 45. 775.]\n",
      "[ 35. 296.]\n",
      "[ 31. 285.]\n",
      "[ 42. 359.]\n",
      "[ 45. 224.]\n",
      "[ 44. 251.]\n",
      "[ 49. 352.]\n",
      "[  44. 1097.]\n",
      "[  87. 5127.]\n",
      "[ 100. 2958.]\n",
      "[  98. 2432.]\n",
      "[  98. 1361.]\n",
      "[  67. 2880.]\n",
      "[ 65. 812.]\n",
      "[  65. 2508.]\n",
      "[  67. 1463.]\n",
      "[ 92. 606.]\n",
      "[ 62. 922.]\n",
      "[  43. 1285.]\n",
      "[ 32. 597.]\n",
      "[ 64. 525.]\n",
      "[ 77. 727.]\n",
      "[ 92. 983.]\n",
      "[ 86. 759.]\n",
      "[ 72. 593.]\n",
      "[ 45. 603.]\n",
      "[ 85. 512.]\n",
      "[ 82. 398.]\n",
      "[ 36. 490.]\n",
      "[ 32. 427.]\n",
      "[ 35. 736.]\n",
      "[ 37. 417.]\n",
      "[101. 746.]\n",
      "[ 98. 515.]\n",
      "[ 31. 891.]\n",
      "[ 40. 679.]\n",
      "[  57. 1309.]\n",
      "[ 59. 212.]\n",
      "[ 45. 265.]\n",
      "[ 37. 262.]\n",
      "[ 32. 241.]\n",
      "[ 41. 730.]\n",
      "[  37. 2110.]\n",
      "[  31. 1822.]\n",
      "[  38. 1888.]\n",
      "[  96. 2238.]\n",
      "[  94. 2299.]\n",
      "[ 88. 886.]\n",
      "[ 99. 366.]\n",
      "[ 88. 351.]\n",
      "[ 51. 897.]\n",
      "[ 64. 917.]\n",
      "[ 85. 859.]\n",
      "[  66. 2115.]\n",
      "[  86. 2648.]\n",
      "[  85. 2821.]\n",
      "[ 95. 266.]\n",
      "[ 57. 384.]\n",
      "[ 64. 275.]\n",
      "[ 35. 188.]\n",
      "[ 40. 284.]\n",
      "[ 38. 217.]\n",
      "[ 35. 173.]\n",
      "[ 25. 231.]\n",
      "[ 26. 405.]\n",
      "[ 28. 380.]\n",
      "[ 29. 280.]\n",
      "[ 93. 342.]\n",
      "[ 67. 269.]\n",
      "[ 63. 184.]\n",
      "[ 54. 827.]\n",
      "[ 50. 256.]\n",
      "[ 72. 275.]\n",
      "[ 70. 642.]\n",
      "[  68. 2310.]\n",
      "[ 52. 722.]\n",
      "[  61. 2472.]\n",
      "[  38. 2048.]\n",
      "[  92. 1847.]\n",
      "[ 71. 774.]\n",
      "[  76. 1387.]\n",
      "[  92. 2189.]\n",
      "[ 48. 490.]\n",
      "[  62. 1083.]\n",
      "[ 82. 941.]\n",
      "[ 80. 472.]\n",
      "[ 90. 335.]\n",
      "[ 39. 523.]\n",
      "[  47. 1476.]\n",
      "[  83. 4984.]\n",
      "[ 48. 815.]\n",
      "[ 82. 478.]\n",
      "[ 71. 195.]\n",
      "[ 61. 192.]\n",
      "[ 26. 354.]\n",
      "[ 35. 229.]\n",
      "[ 29. 200.]\n",
      "[ 56. 126.]\n",
      "[ 80. 268.]\n",
      "[ 74. 318.]\n",
      "[ 88. 606.]\n",
      "[  56. 1362.]\n",
      "[ 31. 142.]\n",
      "[ 61. 121.]\n",
      "[35. 52.]\n",
      "[ 36. 108.]\n",
      "[ 39. 107.]\n"
     ]
    }
   ],
   "source": [
    "midi = convert_to_midi(gen_seqs[0], time_scale=2)\n",
    "midi.save(\"ohboi1.mid\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = get_generator()\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "train_generator(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "  devices = sess.list_devices()\n",
    "\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "midi = convert_to_midi(generated_notes)\n",
    "\n",
    "for msg in midi:\n",
    "    print(msg)\n",
    "    \n",
    "midi.save('test5.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
